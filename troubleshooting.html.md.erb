---
title: Troubleshooting PCF Metrics
owner: PCF Metrics
list_style_none: true
---

<strong><%= modified_date %></strong>

This topic describes how to resolve common issues experienced while operating or using Pivotal Cloud Foundry (PCF) Metrics.

## <a id='insufficient-resources'></a> Insufficient Resources

<table border='1' class='nice'>
<tr>
  <th width="22%">Error</th>
  <td><code>Insufficient Resources</code>
  </td>
</tr>
<tr>
  <th>Cause</th>
  <td>Your PCF deployment has insufficient Diego resources to handle the apps pushed as part of a PCF Metrics installation.
  <br><br>
  The PCF Metrics tile deploys the following apps:
  <table>
    <tr>
      <th>App</th>
      <th>Memory</th>
      <th>Disk</th>
    </tr>
    <tr>
      <td><code>metrics-queue</code><sup>*</sup></td>
      <td>512&nbsp;MB</td>
      <td>1&nbsp;GB</td>
    </tr>
    <tr>
      <td><code>logs-queue</code><sup>*</sup></td>
      <td>256&nbsp;MB</td>
      <td>1&nbsp;GB</td>
    </tr>
    <tr>
      <td><code>metrics-ingestor</code><sup>*</sup></td>
      <td>512&nbsp;MB</td>
      <td>1&nbsp;GB</td>
    </tr>
    <tr>
      <td><code>metrics</code></td>
      <td>1&nbsp;GB</td>
      <td>2&nbsp;GB</td>
    </tr>
    <tr>
      <td><code>metrics-ui</code></td>
      <td>256&nbsp;MB</td>
      <td>1&nbsp;GB</td>
    </tr>
    <tr>
      <td><code>metrics-alerting</code></td>
      <td>1&nbsp;GB</td>
      <td>2&nbsp;GB</td>
    </tr>
  </table>

   <sup>*</sup>Your number of instances of each of these applications depend on your <a href="./sizing.html">sizing</a> needs.
   You configure these instance counts as part of the <a href="./installing.html#data">Data Store</a> pane of the tile.</p></td></td>
</tr>
<tr>
  <th>Solution</th>
  <td>Increase the number of Diego cells so the PCF deployment can support the apps that are pushed as part of the PCF Metrics installation:
  <br>
  <br>
  <ol>
  <li>Navigate to the <b>Resource Config</b> section of the PAS tile.</li>
  <li>In the <b>Diego Cell</b> row, add another <b>Instance</b>.</li>
  </ol>
</tr>
</table>

## <a id='missing-logs'></a> Missing Specific Logs

<table>
  <tr>
    <th>Error</th>
    <td>Logs are missing for a specific application or a subset of logs are bing skipped.</td>
  </tr>
  <tr>
    <th>Cause</th>
    <td>PCF Metrics does not store logs with messages containing non-UTF-8 characters or logs with application GUIDs that are not standard UUID.</td>
  </tr>
  <tr>
    <th>Solution</th>
    <td>Remove non-UTF-8 characters from log messages and ensure it is created with a correct application GUID.
</td>
  </tr>
</table>

## <a id='high-cpu'></a> High CPU on PostgreSQL VM

<table>
  <tr>
    <th>Error</th>
    <td>PostgreSQL VM CPU is over 80% for an extended period of time.</td>
  </tr>
  <tr>
    <th>Cause</th>
    <td>The PostgreSQL VM does not have enough CPU allocated or enough space allocated for storage.</td>
  </tr>
  <tr>
    <th>Solution</th>
    <td>
        Increase the size of the PostgreSQL VM
        <br><br>
        <ol>
          <li>
              If the disk storage is below 85%, ssh to the PostgreSQL VM and check the load average (with <code>uptime</code> or <code>top</code>).
              If the load average is high, increase the CPU allocated for the PostgreSQL VM.
              Spikes in CPU may occur during higher than normal traffic load. This is normal.
          </li>
          <li>If the disk storage is over 85%, increase the storage space allocated for the PostgreSQL VM.</li>
          <li>The CPU may remain high for a period of time after the upgrade.</li>
        </ol>
    </td>
  </tr>
</table>

## <a id="too-many-clients"></a>Too Many Clients Error

<table>
  <tr>
      <th>Error</th>
      <td>You encounter <code>sorry, too many clients already</code> errors when accessing the PCF Metrics UI in your browser.</td>
  </tr>
  <tr>
      <th>Cause</th>
      <td>Your PostgreSQL is running out of disk space, causing reduced performance and a spike of open connections.
          Possible causes:
      <br><br>
      <ol>
        <li>If you are on <code>1.6.0</code>, your PostgreSQL instance does not have automatic pruning configured. This was introduced in <code>1.6.1</code></li>
        <li>Your app emits a lot of logs and is taking up disk space very quickly.</li>
      </ol>
    </td>
  </tr>
  <tr>
      <th>Solution</th>
      <td>
        <ol>
          <li>Upgrade your version to <code>1.6.1</code> and configure your <b>Logs Max Retention Percentage</b> and
            <b>Logs Disk Size Pruning Interval</b>.
          <li>
            Decrease the Logs Retention Window and increase the PostgreSQL Persistent Disk
            <br><br>
            <ol>
              <li>Navigate to the <b>Metrics Components Config</b> section of the PCF Metrics Tile.</li>
              <li>Decrease the Logs Retention Window to a smaller number to free up space in PostgreSQL.</li>
              <li>Navigate to the <b>Resource Config</b> section of the PCF Metrics Tile.</li>
              <li>Increase the Persistent Disk size of PostgreSQL Server to at least twice the current size.</li>
            </ol>
          </li>
        </ol>


  </tr>
</table>

## <a id="fetch-apps"></a>Failed to Fetch Apps
<table>
  <tr>
      <th>Error</th>
      <td>Even though you entered the correct UAA credentials, the metrics app fails to fetch the list of apps.</td>
  </tr>
  <tr>
      <th>Cause</th>
      <td>The browser plugins or cookies inject extraneous content in requests to Cloud Controller API, causing it to reject the request.</td>
  </tr>
  <tr>
      <th>Solution</th>
      <td>Confirm the problem and clear the browser, as follows:
      <ol>
        <li>Try the browser's incognito mode to see if the metrics app is able to fetch the list of apps.
             If this works, the problem is likely cookies or plugins.</li>
        <li>Clear your browser cookies and plugins.</li>
       </ol>
       </td>
  </tr>
</table>

## <a id="redis-full"></a>Redis Temporary Datastore Stops Accepting Metrics
<table>
  <tr>
      <th>Error</th>
      <td>
            You see both these problems:<ul>
            <li>Metrics stop appearing on the UI.</li>
            <li>When you run <code>cf metrics-ingestor logs</code>, you see the following entry in the Ingestor logs:<br>
                <code>MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk.
                Commands that may modify the data set are disabled. Please check Redis logs for details about the error.</code></li>
           </ul>
      </td>
  </tr>
  <tr>
      <th>Cause</th>
      <td>The Redis datastore is full. The component is out of memory or persistent disk space.</td>
  </tr>
  <tr>
      <th>Solution</th>
      <td>Confirm the problem and scale up Redis, as follows:
      <ol>
        <li>On the <strong>Metrics</strong> tile, click the <strong>Status</strong> tab and
            look to see if the memory or persistent disk usage of the Redis job is over 80%.</li>
        <li>Scale up the Redis component. For more information, see <a href=".//sizing.html#temp-datastore">
            Scale the Temporary Datastore (Redis)</a>.</li>
       </ol>
       </td>
  </tr>
</table>

#### <a id="no-results-mysql"></a> Received No Results Back from MySQL - Failing

<table border='1' class='nice'>
<tr>
  <th width="22%">Error</th>
  <td><code>Received no results back from mysql - failing</code>
  </td>
</tr>
<tr>
  <th>Cause</th>
  <td>The Ingestor is not functioning properly.</td>
</tr>
<tr>
  <th>Solution</th>
  <td>
  <ol>
  <li>From the cf CLI, target the <code>system</code> org and <code>metrics-v1-6</code> space of your PCF deployment:</li>
    <pre class="terminal">$ cf target -o system -s metrics-v1-6</pre>
    <li>Run <code>cf apps</code> to see if these apps are running:
      <ul>
        <li><code>metrics-ingestor</code></li>
        <li><code>metrics-queue</code></li>
      </ul>
    </li>
    <li>
      If the apps are not running, run the following commands to start them:
    </li>
       <pre class="terminal">$ cf start metrics-ingestor<br>$ cf start metrics-queue</pre>
    <li>
      Run the following commands and search the app logs for <code>ERROR</code> messages containing additional information:
    </li>
     <pre class="terminal">$ cf logs metrics-ingestor --recent<br>$ cf logs metrics-queue --recent</pre>
     <p class="note"><strong>Note</strong>: In some cases, the apps cannot communicate due to TLS certificate verification failure.
      If your deployment uses self-signed certs, ensure the <b>Disable SSL certificate verification for this environment</b> box is selected
      in the PAS <b>Networking</b> pane.</p>
  </ol>
</tr>
</table>

#### <a id="failed-connect-mysql"></a>Failed to Connect to MySQL

<table border='1' class='nice'>
<tr>
  <th width="22%">Error</th>
  <td><code>Failed to connect to mysql</code>
  </td>
</tr>
<tr>
  <th>Cause</th>
  <td>MySQL is not running properly.</td>
</tr>
<tr>
  <th>Solution</th>
  <td>
  <ol>
    <li>
    Check the logs of the MySQL Server and MySQL Proxy jobs for errors.
      <ul><li>You can download the logs from the PCF Metrics tile under the <b>Status</b> tab.</li></ul>
    </li>
    <li>From the cf CLI, target the <code>system</code> org and <code>metrics-v1-6</code> space of your PCF deployment:</li>
    <pre class="terminal">$ cf target -o system -s metrics-v1-6</pre>
    <li>
    Run the following command and ensure the security group can access the MySQL jobs:
    <p class="note"><strong>Note</strong>: PCF Metrics creates a default security group to allow all traffic to its apps.</p>
    </li>
    <pre class="terminal">$ cf security-group metrics-api</pre>
  </ol></td>
</tr>
</table>

#### <a id="never-recieved-app-logs"></a> Never Received App Logs

<table border='1' class='nice'>
<tr>
  <th width="22%">Error</th>
  <td><code>Never received app logs - something in the firehose -> PostgreSQL flow is broken</code>
  </td>
</tr>
<tr>
  <th>Cause</th>
  <td>Ingestor is not inserting logs correctly.</td>
</tr>
<tr>
  <th>Solution</th>
  <td>
  <ol>
  <li>From the cf CLI, target the <code>system</code> org and <code>metrics-v1-6</code> space of your PCF deployment:</li>
    <pre class="terminal">$ cf target -o system -s metrics-v1-6</pre>
    <li>Run <code>cf apps</code> to see if these apps are running:
      <ul>
        <li><code>metrics-ingestor</code></li>
        <li><code>logs-queue</code></li>
      </ul>
    </li>
    <li>
      If the apps are not running, run the following commands to start them:
    </li>
      <pre class="terminal">$ cf start metrics-ingestor<br>$ cf start logs-queue</pre>
    <li>
      Run the following commands and search the app logs for <code>ERROR</code> messages containing additional information:
    </li>
     <pre class="terminal">$ cf logs metrics-ingestor --recent<br>$ cf logs logs-queue --recent</pre>
     <p class="note"><strong>Note</strong>: In some cases, you might discover a failure to communicate with Loggregator in the form of a bad handshake error.
         <br><br>Ensure the <b>Loggregator Port</b> setting in the PAS tile <b>Networking</b> pane is set to the correct value.
         For deployments on AWS not using an ALB, it is <code>4443</code>. Otherwise, it is <code>443</code>.
         <br><br>
         If the <b>metrics-ingestor</b> logs shows <b>Aggregation Stored Procedures key is not in redis</b>,
         stop the <b>metrics-ingestor</b> application, restart Redis, and start the <b>metrics-ingestor</b> application again.
         <br><br>
         Redis is used for metrics and logs aggregation.
         If there is an error loading the stored procedure, the ingestor will fail to ingest both logs and metrics.
      </p>
  </ol>
  </td>
</tr>
</table>

#### <a id="metrics-events-not-available"></a>Metrics and Events Not Available

<table border='1' class='nice'>
<tr>
  <th width="22%">Error</th>
  <td>
      <code>Network metrics are not available.</code><br>
      <code>Container metrics are not available.</code><br>
      <code>App events are not available.</code>
  </td>
</tr>
<tr>
  <th>Cause</th>
  <td>PCF Metrics is misconfigured and the frontend API does not receive logs from MySQL.</td>
</tr>
<tr>
  <th>Solution</th>
  <td>
  <ol>
  <li>From the cf CLI, target the <code>system</code> org and <code>metrics-v1-6</code> space of your PCF deployment:</li>
    <pre class="terminal">$ cf target -o system -s metrics-v1-6</pre>
    <li>
      Run the following command to check the app logs and investigate the error:
    </li>
     <pre class="terminal">$ cf logs metrics --recent</pre>
  </ol>
  </td>
</tr>
</table>

#### <a id="logs-histograms-not-available"></a>Logs and Histograms Not Available

<table border='1' class='nice'>
<tr>
  <th width="22%">Error</th>
  <td>
    <code>Logs are not available.</code><br>
    <code>Histograms are not available.</code>
  </td>
</tr>
<tr>
  <th>Cause</th>
  <td>PCF Metrics is misconfigured and the frontend API does not receive logs from PostgreSQL.</td>
</tr>
<tr>
  <th>Solution</th>
  <td>
  <ol>
  <li>From the cf CLI, target the <code>system</code> org and <code>metrics-v1-6</code> space of your PCF deployment:</li>
    <pre class="terminal">$ cf target -o system -s metrics-v1-6</pre>
    <li>
      Run the following command to check the app logs and investigate the error:
    </li>
     <pre class="terminal">$ cf logs metrics --recent</pre>
  </ol>
  </td>
</tr>
</table>

## <a id='ui'></a> No Logs or Metrics in the UI

In some cases, the PCF Metrics UI might not display metrics and logs after successfully deploying.

Follow the steps in this section to help locate the app or component causing the problem.

### Step 1: Check your Load Balancer Configuration

If you use a load balancer, the event-stream mechanism used by the Metrics UI might be blocked. See the table below to resolve this error.

If you do not use a load balancer, or this issue does not apply to your deployment, proceed to the next step.

<table>
  <tr>
    <th>Error</th>
    <td>In the case of a customer using an F5 load balancer, metrics and logs were not visible in the UI despite successful ingestion and no UI errors reported.</td>
  </tr>
  <tr>
    <th>Cause</th>
    <td>The root of the issue was the traffic of type text/event-stream was blocked by the F5 load balancer.</td>
  </tr>
  <tr>
    <th>Solution</th>
    <td>When F5 was configured to allow event-stream traffic, the issue was resolved.
</td>
  </tr>
</table>

### Step 2: Check the PCF Metrics Apps

1. From Ops Manager, click the PAS Tile.
  1. Click the **Credentials** tab.
  1. Under the **UAA** job, next to **Admin Credentials**, click **Link to Credential**.
  1. Record the username and password for use in the next step.

1. Log in to the Cloud Foundry Command Line Interface (cf CLI) using the credentials from the previous step.
  <pre class="terminal">$ cf login -a http<span>s</span>://api.YOUR-SYSTEM-DOMAIN -u admin -p PASSWORD</pre>

1. When prompted, select the `system` org and the `metrics-v1-6` space.

1. Ensure that the output displays the following apps, each in a `started` state:
  * `metrics-ingestor`
  * `metrics-queue`
  * `logs-queue`
  * `metrics`
  * `metrics-ui`
  * `metrics-alerting`

1. Check the logs of each app for errors using the following command:
  <pre class="terminal">$ cf logs APP-NAME --recent</pre>
  If you do not see any output, or if you did not find any errors, proceed to the next step.


### Step 3: Check the Metrics Ingestor

  1. To get a higher level of detail from the metrics-ingestor application, set the LOG_LEVEL env variable:
  <pre class="terminal">$ cf set-env metrics-ingestor LOG_LEVEL DEBUG</pre>
  1. To apply this setting, restage the application:
  <pre class="terminal">$ cf restage metrics-ingestor</pre>
  1. Run the following command to stream logs:
  <pre class="terminal">$ cf logs metrics-ingestor</pre>
  1. Watch the logs emitted by the `metrics-ingestor` app for errors. See the list below for common errors:
      * **Aggregation Stored Procedures key is not in redis**: Redis may have been restarted or is in a bad state.
          Stop the `metrics-ingestor` app. Restart redis. Start the `metrics-ingestor` app again.
      * **Cannot connect to the firehose**: PCF Metrics creates a UAA user to authenticate the connection to the Firehose.
          This user must have the `doppler.firehose` authority.
      * **Could not find service with name: metrics-forwarder**: The Metrics Forwarder Tile is not installed.
          Metrics will not display custom metrics without the Metrics Forwarder Tile but will otherwise function normally.
      * **WebSocket Disconnects**: If you see WebSocket disconnects logs in the Ingestor app, consider adding additional Ingestor instances.
          The Firehose might be dropping the Ingestor connection to avoid back pressure.
      * **Redis errors**: Investigate redis logs, for instructions see [Advanced Troubleshooting with the BOSH CLI](https://docs.vmware.com/en/VMware-Tanzu-Operations-Manager/3.0/vmware-tanzu-ops-manager/install-trouble-advanced.html).
           Many possible solutions start with restarting redis.

1. If the app is started and you do not find any errors, proceed to the next step.

### Step 4: Check the log-queue

  1. To get a higher level of detail from the logs-queue application, set the LOG_LEVEL env variable:
  <pre class="terminal">$ cf set-env logs-queue LOG_LEVEL DEBUG</pre>
  1. To apply this setting, restage the application:
  <pre class="terminal">$ cf restage logs-queue</pre>
  1. Run the following command to stream logs:
  <pre class="terminal">$ cf logs logs-queue</pre>
  1. Watch the logs emitted by the `logs-queue` app for errors.
      * A common error is that the app cannot connect to PostgreSQL
        due to the application security group (ASG) being deleted.
        This ASG allows the logs-queue application to create a network connection to the PostgreSQL VM.
        You can run `cf security-group metrics-api` to see if the ASG exists.
        If the ASG is not present, see [Creating Application Security Groups](https://docs.cloudfoundry.org/concepts/asg.html)
        to recreate it.
      * **Could not find service with name: metrics-forwarder**: The Metrics Forwarder Tile is not installed.
          Metrics will not display custom metrics without the Metrics Forwarder Tile but will otherwise function normally.

1. If the app is started and you do not find any errors, proceed to the next step.


### Step 5: Check MySQL

1. From Ops Manager, select the PCF Metrics tile.

1. Under the **Status** tab, record the IP of a **MySQL Server** node.

1. Use `bosh ssh` to access the VM from the previous step.
   For instructions, see [Advanced Troubleshooting with the BOSH CLI](https://docs.vmware.com/en/VMware-Tanzu-Operations-Manager/3.0/vmware-tanzu-ops-manager/install-trouble-advanced.html).

1. Log in to mysql by running `mysql -u USERNAME -p PASSWORD`
  <p class="note"><strong>Note</strong>: If you do not know the username and password,
    you can run `cf env metrics-queue` with the <code>system</code> org and the <code>metrics-v1-6</code> space targeted.</p>

1. Verify that the database was bootstrapped correctly:
  1. Run `show databases` and check for a `metrics` database.
      1. If there is no `metrics` database, the `Push PCF Metrics Components Errand` errand of the BOSH release might not have run or succeeded.
         Ensure the errand is selected in the tile configuration and update the tile.

1. Run `use metrics` to select the `metrics` database:
   <pre class="terminal">mysql> use metrics;</pre>

1. Run `show tables` and ensure you see the following tables:
   <pre class="terminal">mysql> show tables;
   +-----------------------------+
   | Tables\_in\_metrics           |
   +-----------------------------+
   | app\_event                   |
   | app\_metric                  |
   | app\_metric\_rollup           |
   | schema\_version              |
   | app\_metric\_identifier       |
   +-----------------------------+
   </pre>

1. Enter the following query several times to verify that the value returned does not decrease over time:
  <pre class="terminal">mysql> select count(*) from metrics.app\_metric\_identifier where timestamp_minute > ((UNIX\_TIMESTAMP() - 60) * POW(10, 3));</pre>
  This command displays the rate at which metrics flow in over the last minute.
   If the command returns `0` or a consistently decreasing value, the problem is likely further up in ingestion;
         proceed to the next step.

### Step 6: Check the Metrics Queue
  1. To get a higher level of detail from the metrics-queue application, set the LOG_LEVEL env variable:
  <pre class="terminal">$ cf set-env metrics-queue LOG_LEVEL DEBUG</pre>
  1. To apply this setting, restage the application:
  <pre class="terminal">$ cf restage metrics-queue</pre>
  1. Run the following command to stream logs:
  <pre class="terminal">$ cf logs metrics-queue</pre>
  1. Watch the logs emitted by the `metrics-queue` app for errors.
      * A common error is that the app cannot connect to MySQL
        due to the application security group (ASG) being deleted.
        This ASG allows the logs-queue application to create a network connection to the MySQL VM.
        You can run `cf security-group metrics-api` to see if the ASG exists.
        If the ASG is not present, see [Creating Application Security Groups](https://docs.cloudfoundry.org/concepts/asg.html)
        to recreate it.
      * **Could not find service with name: metrics-forwarder**: The Metrics Forwarder Tile is not installed.
          Metrics will not display custom metrics without the Metrics Forwarder Tile but will otherwise function normally.

1. If the app is started and you do not find any errors, proceed to the next step.

## <a id='mysql'></a> MySQL Failure

In some cases, a MySQL server might fail to restart.
The following two sections describe the known conditions that cause this failure as well as steps for diagnosing and resolving them.

### Cause 1: Monit Timed Out

#### Diagnose

Follow these steps to see if a `monit` time-out caused the MySQL node restart to fail:

1. Use `bosh ssh` to access the failing node, using the IP address in the Ops Manager Director tile **Status** tab.
   For instructions, see [Advanced Troubleshooting with the BOSH CLI](https://docs.vmware.com/en/VMware-Tanzu-Operations-Manager/3.0/vmware-tanzu-ops-manager/install-trouble-advanced.html).
1. Run `monit summary` and check the status of the `galera-init` job.
1. If the status of the `galera-init` job is `Execution Failed`, open the following file: `/var/vcap/sys/log/pxc-mysql/galera-init.log`.
  1. If the last line of the log indicates that MySQL started without issue, such as in the example below,
     `monit` likely timed out while waiting for the job to report healthy. Follow the steps below to resolve the issue.
  <pre class="terminal">
  {"timestamp":"1536851105.372446537","source":"/var/vcap/packages/galera-init/bin/galera-init","message":"/var/vcap/packages/galera-init/bin/galera-init.galera-init started","log_level":1,"data":{}}
  </pre>

#### Resolve

Run the following commands to return the `galera-init` job to a healthy state:

1. Run `monit unmonitor galera-init`.
1. Run `monit monitor galera-init`.
3. Run `monit summary` and confirm that the output lists `galera-init` as `running`.

### Cause 2: Bin Logs Filled up the Disk

#### Diagnose

1. Use `bosh ssh` to access the failing node.
   For instructions, see [Advanced Troubleshooting with the BOSH CLI](https://docs.vmware.com/en/VMware-Tanzu-Operations-Manager/3.0/vmware-tanzu-ops-manager/install-trouble-advanced.html).
1. Open the following log file: `/var/vcap/sys/log/pxc-mysql/mysql.err.log`.
1. If you see log messages that indicate insufficient disk space, the [persistent disk](https://bosh.io/docs/persistent-disks/) is likely storing too many bin logs.
   Confirm insufficient disk space by doing the following:
  1. Run `df -h`.
      1. Ensure that you see the `/var/vcap/store` folder is at or over `90%` usage.
  1. Navigate to `/var/vcap/store/pxc-mysql` and run `ls -al`.
      1. Ensure that you see many files named with the format `mysql-bin.########`.

In MySQL for PCF, the server node does not make use of these logs and you can remove all except the most recent bin log.
Follow the steps below to resolve the issue.

#### Resolve

1. Log in to mysql by running `mysql -u USERNAME -p PASSWORD`
  <p class="note"><strong>Note</strong>: If you do not know the username and password, you can run `cf env metrics-queue` with the <code>system</code> org and the <code>metrics-v1-6</code> space targeted.</p>
1. Run `use metrics;`.
1. Run the following command:
<pre class="terminal">mysql> PURGE BINARY LOGS BEFORE 'YYYY-MM-DD HH:MM:SS'; </pre>

#### Edit Your MySQL Server Configuration
1. From Ops Manager, click the PCF Metrics Tile.
1. Navigate to the Resource Config section of the PCF Metrics Tile.
1. Increase the Persistent Disk size of MySQL Server to at least twice the current size.

##<a id='syslog'></a> Forward PCF Metrics Logs to a Syslog Endpoint

When using PCF Metrics 1.6 or higher on PCF 2.4 and beyond, you can configure the tile to forward its logs to a syslog endpoint for troubleshooting. Please see the "Forward PCF Metrics Logs to a Syslog Endpoint" section under the [Configure the PCF Metrics Tile](./installing.html#step2) docs for more details.

## <a id="push-apps-red-herring"></a>Service metrics-forwarder does not exist
<table>
  <tr>
      <th>Error</th>
      <td>Service metrics-forwarder does not exist.</td>
  </tr>
  <tr>
      <th>Cause</th>
      <td>The Metrics Forwarder Tile is not installed.</td>
  </tr>
  <tr>
      <th>Solution</th>
      <td>Install the Metrics Fowarder Tile if you would like custom metrics; otherwise the error can be ignored.
      The service is optional.</td>
  </tr>
</table>


## <a id="http-metrics-unavailable"></a>Metrics API Unavailable
<table>
  <tr>
      <th>Error</th>
      <td>Metrics url shows Metrics API Unavailable.</td>
  </tr>
  <tr>
      <th>Cause</th>
      <td>The URL is http.</td>
  </tr>
  <tr>
      <th>Solution</th>
      <td>Go the the https version of the metrics URL.</td>
  </tr>
</table>
